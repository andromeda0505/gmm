{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from gmm import GELEstimator\n",
    "np.random.seed(94305)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Empirical Likelihood Estimation\n",
    "\n",
    "We want to estimate a parameter implicitly defined as a solution to a moment condition $g(Z; \\theta) = 0$. \n",
    "\n",
    "GMM proceeds by minimizing the quadratic form $Q(\\theta) = g(Z; \\theta)'Wg(Z; \\theta)$, where $W$ is a positive definite weighting matrix. The choice of the weighting matrix is crucial for the efficiency of the estimator.\n",
    "\n",
    "GEL sidesteps the choice of the weighting matrix by minimizing the empirical likelihood function. The empirical likelihood function is defined as the maximum of the likelihood function subject to the moment condition.\n",
    "\n",
    "The (log) empirical likelihood function is defined as:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\max_{p \\in \\mathcal{P}} \\sum_{i=1}^n \\log p_i\n",
    "$$\n",
    "\n",
    "subject to the moment condition $$p_i g(Z; \\theta) = 0$$\n",
    "and adding up $\\sum_{i=1}^n p_i = 1$.\n",
    "\n",
    "where $\\mathcal{P}$ is the set of all probability distributions on $\\{1, \\ldots, n\\}$. At a first glance, this problem seems harder, since we need to solve for a weight vector $p$, which is typically of much higher dimension than the parameter $\\theta$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Imbens, Spady, and Johnson (1998)](https://scholar.harvard.edu/sites/scholar.harvard.edu/files/imbens/files/information_theoretic_approaches_to_inference_in_moment_condition_models.pdf) show that minimizing the KLIC instead of the log empirical likelihood produces better behavior under `mild' misspecification. The corresponding Exponential Tilting estimator is defined as solving\n",
    "\n",
    "$$\n",
    "\\max_{\\theta, p_i} - \\sum_{i=1}^n p_i \\log p_i\n",
    "$$\n",
    "\n",
    "subject to the moment condition $p_i g(Z; \\theta) = 0$ and $\\sum_{i=1}^n p_i = 1$. \n",
    "\n",
    "The estimating equations are difficult to solve directly, so we instead use the saddlepoint representation\n",
    "\n",
    "$$\n",
    "\\max_{\\theta} \\min_{t} \\sum_{i=1}^n \\exp(t' g(Z_i; \\theta))\n",
    "$$\n",
    "\n",
    "that concentrates out the weight vector.\n",
    "The inner function is strictly convex in $t$, and can be solved quickly. The outer function iterates over candidate values of $\\theta$. We implement this approach in `GELEstimator`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Problems\n",
    "\n",
    "### estimating a mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.01999056, 0.03015686],\n",
       "       [2.04451165, 0.03196784]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1000\n",
    "X = np.random.normal(np.array([1, 2]), size=(n, 2))\n",
    "np.c_[X.mean(axis=0), np.sqrt(n/(n-1) * X.var(axis=0)/n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alal/Desktop/gmm/gmm/gel.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 - np.exp(v)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.01999208, 0.03015686],\n",
       "       [2.04451432, 0.03196784]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moment_cond_mean = lambda D, theta: D - theta\n",
    "\n",
    "gelmod = GELEstimator(m = moment_cond_mean)\n",
    "gelmod.fit(X, np.zeros(2))\n",
    "gelmod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analytic and GEL estimates identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgp(n=100_000, beta=np.array([-0.5, 1.2]), rho=0.7, pi=np.array([0.5, -0.1])):\n",
    "    ε = np.random.normal(0, 1, n)\n",
    "    z = np.random.normal(0, 1, n * pi.shape[0]).reshape(n, pi.shape[0])\n",
    "    # Generate endogenous x, influenced by the instrument\n",
    "    x = z @ pi + ε * rho + np.random.normal(0, 1, n)\n",
    "    X = np.c_[np.ones(n), x]\n",
    "    # heteroskedasticity\n",
    "    y = X @ beta + ε + np.random.normal(0, 1 + 0.5 * (X[:, 1] > 0), n)\n",
    "    return y, X, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.4973      0.005    -97.051      0.000      -0.507      -0.487\n",
      "x1             1.2029      0.005    264.132      0.000       1.194       1.212\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "y, X, z = dgp(rho = 0)\n",
    "print(sm.OLS(y, X).fit(cov_type = \"HC2\").summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Estimation via EL/ET__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alal/Desktop/gmm/gmm/gel.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 - np.exp(v)\n",
      "/home/alal/miniforge3/envs/py311/lib/python3.11/site-packages/scipy/optimize/_numdiff.py:590: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.49733268,  0.00512474],\n",
       "       [ 1.20289956,  0.0057488 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def moment_condition_ols(D, θ):\n",
    "    y, X = D[:, 0], D[:, 1:]\n",
    "    r = y - X @ θ\n",
    "    return X * r[:, None]\n",
    "\n",
    "D = np.c_[y, X]\n",
    "gelmod = GELEstimator(m = moment_condition_ols)\n",
    "k = X.shape[1]\n",
    "gelmod.fit(D, np.zeros(k))\n",
    "gelmod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.4993      0.005   -106.700      0.000      -0.508      -0.490\n",
      "x1             1.6436      0.003    528.685      0.000       1.638       1.650\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "y, X, Z = dgp(rho = 1)\n",
    "print(sm.OLS(y, X).fit(cov_type = \"HC2\").summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2032850786188123, 0.008980883046787019)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2SLS via control function\n",
    "D = X[:, 1]\n",
    "Dhat = sm.OLS(D, Z).fit().predict()\n",
    "tslsreg = sm.OLS(y, np.c_[sm.add_constant(D), D - Dhat]).fit(cov_type=\"HC1\")\n",
    "tslsreg.params[1], tslsreg.bse[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unbiased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alal/Desktop/gmm/gmm/gel.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 - np.exp(v)\n",
      "/home/alal/miniforge3/envs/py311/lib/python3.11/site-packages/scipy/optimize/_numdiff.py:590: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n",
      "/home/alal/miniforge3/envs/py311/lib/python3.11/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.14549332,  0.00521293],\n",
       "       [ 1.20631701,  0.00526045]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def moment_condition_iv(D, θ):\n",
    "    y, X, Z = D[:, 0], D[:, 1:3], D[:, 3:]\n",
    "    r = y - X @ θ\n",
    "    return Z * r[:, None]\n",
    "\n",
    "\n",
    "D = np.c_[y, X, Z]\n",
    "k = X.shape[1]\n",
    "gelmod = GELEstimator(m=moment_condition_iv)\n",
    "gelmod.fit(D, np.zeros(k))\n",
    "gelmod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Endogenous coefficient is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Problems \n",
    "\n",
    "### Lin Regression\n",
    "\n",
    "$$\n",
    "Y_i = \\alpha + \\tau Z_i + X_i' \\beta + Z_i \\tilde{X}_i' \\gamma + \\epsilon_i\n",
    "$$\n",
    "\n",
    "where $\\tilde{X}_i = X_i - \\bar{X}$ is the centered version of $X_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "X = np.random.normal(0, 1, n * 2).reshape(n, 2)\n",
    "Y0 = X[:, 0] + X[:, 0] ** 2 + np.random.uniform(-0.5, 0.5, n)\n",
    "Y1 = X[:, 1] + X[:, 1] ** 2 + np.random.uniform(-1, 1, n)\n",
    "Z = np.random.binomial(1, 0.6, n)\n",
    "Y = Y0 * (1 - Z) + Y1 * Z\n",
    "D = np.c_[Y, Z, X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    1.0189</td> <td>    0.117</td> <td>    8.721</td> <td> 0.000</td> <td>    0.789</td> <td>    1.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.1907</td> <td>    0.149</td> <td>    1.281</td> <td> 0.201</td> <td>   -0.102</td> <td>    0.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.9860</td> <td>    0.118</td> <td>    8.365</td> <td> 0.000</td> <td>    0.754</td> <td>    1.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.1129</td> <td>    0.115</td> <td>    0.977</td> <td> 0.329</td> <td>   -0.114</td> <td>    0.340</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -0.8281</td> <td>    0.150</td> <td>   -5.519</td> <td> 0.000</td> <td>   -1.123</td> <td>   -0.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    1.4133</td> <td>    0.142</td> <td>    9.927</td> <td> 0.000</td> <td>    1.134</td> <td>    1.693</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lcccccc}\n",
       "\\toprule\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       1.0189  &        0.117     &     8.721  &         0.000        &        0.789    &        1.248     \\\\\n",
       "\\textbf{x1}    &       0.1907  &        0.149     &     1.281  &         0.201        &       -0.102    &        0.483     \\\\\n",
       "\\textbf{x2}    &       0.9860  &        0.118     &     8.365  &         0.000        &        0.754    &        1.218     \\\\\n",
       "\\textbf{x3}    &       0.1129  &        0.115     &     0.977  &         0.329        &       -0.114    &        0.340     \\\\\n",
       "\\textbf{x4}    &      -0.8281  &        0.150     &    -5.519  &         0.000        &       -1.123    &       -0.533     \\\\\n",
       "\\textbf{x5}    &       1.4133  &        0.142     &     9.927  &         0.000        &        1.134    &        1.693     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.OLS(\n",
    "    Y, np.c_[sm.add_constant(Z), X, Z[:, None] * (X - X.mean(axis=0))]\n",
    ").fit().summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point estimates are consistent, but we do not propagate forward the uncertainty from estimating the sample mean $\\bar{X}$. To do this, we could stack the moment conditions\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "X - \\mu \\\\\n",
    "[X, X - \\mu] (y - [X, X - \\mu] \\beta)\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moment_condition_lin(D, θ):\n",
    "    Y, Z, X = D[:, 0], D[:, 1], D[:, 2:]\n",
    "    n, p = X.shape\n",
    "    mu, beta = θ[:p], θ[p:]\n",
    "    Xcent = X - mu\n",
    "    XX = np.c_[np.ones(n), Z, X, Z[:, None] * Xcent]\n",
    "    r = XX * (Y - XX @ beta)[:, None]\n",
    "    return np.c_[Xcent, r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02681823 0.0657933  0.94022998 0.59071843 0.16238761 0.18472579\n",
      " 0.70219239 0.66758587]\n"
     ]
    }
   ],
   "source": [
    "print(theta_init := np.r_[X.mean(axis=0), np.random.rand(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alal/Desktop/gmm/gmm/gel.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 - np.exp(v)\n",
      "/home/alal/miniforge3/envs/py311/lib/python3.11/site-packages/scipy/optimize/_numdiff.py:590: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gelmod = GELEstimator(m=moment_condition_lin)\n",
    "gelmod.fit(D, theta_init)\n",
    "gelmod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!TODO look into why this fails to converge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
